[{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"animals","dir":"Articles","previous_headings":"","what":"Animals","title":"DCRW examples","text":"illustrate method five example data sets. Blue whale Polar bear Seal Cats Cows Plot world map data:  Plot world map data:  Plot world map data:","code":"whale_2008 = read_csv(\"data/Blue whales Eastern North Pacific 1993-2008 - Argos Data.csv\") |>   # Standardise column names   janitor::clean_names() |>     # Keep only rows for the whale with ID \"2008CA-Bmu-10839\"   filter(individual_local_identifier == \"2008CA-Bmu-10839\") |>    # Replace missing values in 'manually_marked_outlier' with FALSE   mutate(manually_marked_outlier = tidyr::replace_na(manually_marked_outlier, FALSE)) |>    # Round timestamps to the nearest 12 hours   mutate(timestamp = lubridate::round_date(timestamp, \"12 hours\")) |>    # Within each group, keep only the last row (e.g. latest observation per 12-hour block)   group_by(timestamp) |>    slice_tail(n = 1) |>    # Convert the data to a tsibble object (time series tibble)   tsibble::tsibble() |>   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() |>    # Convert back to a regular tibble   as_tibble() |>    # Rename longitude/latitude columns to x and y   rename(x = location_long,          y = location_lat) # Work out x/y ranges with some padding x_range <- range(whale_2008$x, na.rm = TRUE) y_range <- range(whale_2008$y, na.rm = TRUE)  x_pad <- diff(x_range) * 0.05  # 5% padding y_pad <- diff(y_range) * 0.05 # 5% padding  p1 = whale_2008 %>%    ggplot() +   # Country boundaries   geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +      # Whale track and points   geom_path(aes(x = x, y = y, colour = timestamp), alpha = 0.2) +   geom_point(aes(x = x, y = y, colour = timestamp)) +      # Colour scale   viridis::scale_color_viridis() +      # Focus map on whale’s range   coord_sf(     xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),     ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),     expand = FALSE   ) +      # Labels and theme   labs(x = \"Longitude\", y = \"Latitude\", subtitle = \"Blue whale\") +   theme_minimal() +   theme(legend.position = \"none\") p1 polar_low_freq = read_csv(\"data/PB_Argos.csv\") %>%    # Standardise column names   clean_names() %>%    # Convert date_time column to a proper datetime object called 'timestamp'   mutate(timestamp = ymd_hms(date_time)) %>%    # Drop the original date_time column   select(-date_time) %>%    # Round timestamps to the nearest day   mutate(timestamp = lubridate::round_date(timestamp, \"1 day\")) %>%    # Within each group, keep only the first row (e.g. earliest observation per day)   group_by(timestamp) %>%    slice_head(n = 1) %>%    # Convert timestamp to a Date object (drop time-of-day information)   mutate(timestamp = as.Date(timestamp)) %>%    # Convert the data to a tsibble object (time series tibble)   tsibble::tsibble() %>%   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() %>%   # Convert back to a regular tibble   as_tibble() %>%    # Rename longitude/latitude columns to x and y   rename(x = lon, y = lat) # Work out x/y ranges with some padding x_range <- range(polar_low_freq$x, na.rm = TRUE) y_range <- range(polar_low_freq$y, na.rm = TRUE)  x_pad <- diff(x_range) * 0.05  # 5% padding y_pad <- diff(y_range) * 0.05 # 5% padding  p1 %+% polar_low_freq +    # Focus map on polar bear's range   coord_sf(     xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),     ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),     expand = FALSE   ) seal = read_csv(\"data/sealLocs.csv\") %>%    # Keep only rows for the seal with ID \"stephanie\"   filter(id == \"stephanie\") %>%    # Round timestamps to the nearest day   mutate(timestamp = lubridate::round_date(time, \"1 day\")) %>%    # Within each group, keep only the last row (e.g. latest observation per day)   group_by(timestamp) %>%    slice_tail(n = 1) %>%    # Convert timestamp to a Date object (drop time-of-day information)   mutate(timestamp = as.Date(timestamp)) %>%    # Convert the data to a tsibble object indexed by timestamp   tsibble::tsibble(index = timestamp) %>%   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() %>%   # Convert back to a regular tibble   as_tibble() %>%    # Rename longitude/latitude columns to x and y   rename(x = lon,          y = lat) # Work out x/y ranges with some padding x_range <- range(seal$x, na.rm = TRUE) y_range <- range(seal$y, na.rm = TRUE)  x_pad <- diff(x_range) * 0.05  # 5% padding y_pad <- diff(y_range) * 0.05 # 5% padding  p1 %+% seal +    # Focus map on s's range   coord_sf(     xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),     ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),     expand = FALSE   ) cat_mia = read_csv(\"data/Feral cat (Felis catus) - Scotia, NSW.csv\") %>%    clean_names() %>%    mutate(algorithm_marked_outlier = ifelse(is.na(algorithm_marked_outlier),                                                   FALSE,                                                  algorithm_marked_outlier),          manually_marked_outlier = ifelse(is.na(manually_marked_outlier),                                                   FALSE,                                                  manually_marked_outlier),          outlier = algorithm_marked_outlier | manually_marked_outlier) %>%    filter(individual_local_identifier == \"Mia_FC642\") %>%    mutate(timestamp = lubridate::round_date(timestamp, \"20 minutes\")) %>%    tsibble::tsibble() %>%   tsibble::fill_gaps() %>%    slice(-(1:19)) %>%    as_tibble() %>%    rename(x = location_long,          y = location_lat)  cat_max = read_csv(\"data/Feral cat (Felis catus) - Scotia, NSW.csv\") %>%    clean_names() %>%    mutate(algorithm_marked_outlier = ifelse(is.na(algorithm_marked_outlier),                                                   FALSE,                                                  algorithm_marked_outlier),          manually_marked_outlier = ifelse(is.na(manually_marked_outlier),                                                   FALSE,                                                  manually_marked_outlier),          outlier = algorithm_marked_outlier | manually_marked_outlier) %>%    filter(individual_local_identifier == \"Max_MC629\") %>%    mutate(timestamp = lubridate::round_date(timestamp, \"20 minutes\")) %>%    tsibble::tsibble() %>%   tsibble::fill_gaps() %>%    slice(-(1:24)) %>%    as_tibble() %>%    rename(x = location_long,          y = location_lat) cow = read_csv(\"data/export_UQ_GPS.csv\") %>%    clean_names() %>%    filter(partition_key == \"70741400000EB036\") %>%    # The cow data longitude and latitude are swapped! So we set x to be latitude and y to be longitude:   rename(x = latitude,          y = longitude) %>%    mutate(date = date(timestamp)) %>%    select(date, timestamp, x, y) %>%   group_by(date) %>%    mutate(diff = c(2.38, diff(timestamp))) %>%   mutate(missing_rows = map(diff, ~ seq_len(round(. / 2.38)))) %>%   unnest(missing_rows) %>%   mutate(x = ifelse(missing_rows > 1, NA, x),          y = ifelse(missing_rows > 1, NA, y)) %>%    ungroup() %>%    rename(x = x,          y = y)  cow_10 = cow %>% filter(date == \"2024-11-10\") cow_11 = cow %>% filter(date == \"2024-11-11\") cow_12 = cow %>% filter(date == \"2024-11-12\")"},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"collate-data-sets-into-a-list","dir":"Articles","previous_headings":"Results","what":"Collate data sets into a list","title":"DCRW examples","text":"","code":"data_sets = list(   \"cat_max\" = cat_max,   \"cat_mia\" = cat_mia,   \"cow_10\" = cow_10,   \"cow_11\" = cow_11,   \"cow_12\" = cow_12,   \"polar_low_freq\" = polar_low_freq,   \"seal\" = seal,   \"whale_2008\" = whale_2008 )"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"summary-of-missingness-proportion-and-size-of-data-sets","dir":"Articles","previous_headings":"Results","what":"Summary of missingness proportion and size of data sets","title":"DCRW examples","text":"","code":"data_sets %>%    map_dbl(~ mean(is.na(.$x))) %>%    round(2) %>%    as_tibble(rownames = \"data_set\") %>%    rename(proportion_missing = value) %>%    mutate(n = data_sets %>% map_dbl(~ length(.$x))) %>%    arrange(data_set) %>%    knitr::kable()"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"plot-data-sets-on-world-map","dir":"Articles","previous_headings":"Results","what":"Plot data sets on world map","title":"DCRW examples","text":"","code":"# Get country boundaries as an sf object world <- ne_countries(scale = \"medium\", returnclass = \"sf\")  plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- max(diff(y_range) - diff(x_range), 0) / 2  + diff(x_range) * 0.05   y_pad <- max(diff(x_range) - diff(y_range), 0) / 6  + diff(y_range) * 0.05      plots[[i]] = data_sets[[i]] %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_path(aes(x = x, y = y, colour = timestamp), alpha = 0.2) +     geom_point(aes(x = x, y = y, colour = timestamp)) +          # Colour scale     viridis::scale_color_viridis() +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3)"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"fit-models-using-roams-and-classical-methods","dir":"Articles","previous_headings":"Results","what":"Fit models using ROAMS and classical methods","title":"DCRW examples","text":"last 10% points data set left use ‘test set’ later .","code":"results = read_rds(\"data/results.rds\") results = tibble(   name = character(),   data_set = list(),   y_train = list(),   y_oos = list(),   classical = list(),   roams = list(),   classical_oos = list(),   roams_oos = list() )  for (i in 1:length(data_sets)) {      y_all = data_sets[[i]] %>%      select(x, y) %>%      as.matrix()      n = nrow(y_all)   n_train = round(0.9*n)  # 90%/10% train/test split   n_oos = n - n_train      y_train = y_all[1:n_train,]   y_oos = y_all[(n_train+1):n,]      var_est = c(mad(diff(y_train[,1]), na.rm = TRUE)^2,               mad(diff(y_train[,2]), na.rm = TRUE)^2)      build_fn = function(parm) {          phi_coef = parm[1]     Phi = diag(c(1+phi_coef, 1+phi_coef, 0, 0))     Phi[1,3] = -phi_coef     Phi[2,4] = -phi_coef     Phi[3,1] = 1     Phi[4,2] = 1          A = diag(4)[1:2,]     Q = diag(c(parm[2], parm[3], 0, 0))     R = diag(c(parm[4], parm[5]))          x0 = c(y_train[1,], y_train[1,])     P0 = diag(rep(0, 4))          specify_SSM(       state_transition_matrix = Phi,       state_noise_var = Q,       observation_matrix = A,       observation_noise_var = R,       init_state_mean = x0,       init_state_var = P0)   }      model_classical = classical_SSM(     y = y_train,      init_par = c(0.5, var_est, var_est),      build = build_fn,      lower = c(0, rep(1e-12, 4)),     upper = c(1, rep(Inf, 4)),     )      model_roams = robularized_SSM(     y = y_train,     init_par = c(0.5, var_est, var_est),     build = build_fn,     num_lambdas = 20,     cores = 4,     lower = c(0, rep(1e-12, 4)),     upper = c(1, rep(Inf, 4)),     B = 50     )      model_classical = attach_insample_info(model_classical)      model_roams_best = best_BIC_model(model_roams)   model_roams_best = attach_insample_info(model_roams_best)      # Out-of-sample metrics      # Re-create build function with different initial state mean   build_oos_fn = function(par) {      phi_coef = par[1]     Phi = diag(c(1+phi_coef, 1+phi_coef, 0, 0))     Phi[1,3] = -phi_coef     Phi[2,4] = -phi_coef     Phi[3,1] = 1     Phi[4,2] = 1      A = diag(4)[1:2,]     Q = diag(c(par[2], par[3], 0, 0))     R = diag(c(par[4], par[5]))          # Some data sets have first few out-of-sample timepoints missing, so get use first non-missing timepoint to initialise     first_complete_obs = which(!is.na(y_oos[,1]))[1]     x0_oos = c(y_oos[first_complete_obs,],                 y_oos[first_complete_obs,])     P0 = diag(rep(0, 4))      specify_SSM(       state_transition_matrix = Phi,       state_noise_var = Q,       observation_matrix = A,       observation_noise_var = R,       init_state_mean = x0_oos,       init_state_var = P0)   }      classical_oos = oos_filter(     y_oos = y_oos,      model = model_classical,      build = build_oos_fn)      roams_oos = oos_filter(     y_oos = y_oos,      model = model_roams_best,      build = build_oos_fn)      results = results %>%      add_row(       name = names(data_sets)[i],       data_set = list(data_sets[[i]]),       y_train = list(y_train),       y_oos = list(y_oos),       classical = list(model_classical),       roams = list(model_roams_best),       classical_oos = list(classical_oos),       roams_oos = list(roams_oos)     )      cat(\"Data set\", i, \"complete\\n\") }  # Add column containing frequency of measurements for each data set frequencies = c(\"20 minutes\", \"20 minutes\", \"2 minutes and 23 seconds\", \"2 minutes and 23 seconds\", \"2 minutes and 23 seconds\", \"1 day\", \"1 day\", \"12 hours\") results = results %>%    mutate(frequency = frequencies)  # readr::write_rds(results, \"data/results.rds\")"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"compute-and-summarise-results","dir":"Articles","previous_headings":"Results","what":"Compute and summarise results","title":"DCRW examples","text":"","code":"results %>%    mutate(     n = map_dbl(y_train, ~ nrow(.)),     n_complete = map_dbl(y_train, ~ sum(!is.na(.[,1]))),     n_oos = map_dbl(y_oos, ~ nrow(.)),     n_oos_complete = map_dbl(y_oos, ~ sum(!is.na(.[,1]))),          in_sample_detected = map2_dbl(roams, n_complete,                                   ~ .x$prop_outlying * .y),     oos_detected = map_dbl(roams_oos,                            ~ sum(.$outliers_flagged)),          roams_phi = map_dbl(roams, ~ .$par[1]),     classical_phi = map_dbl(classical, ~ .$par[1]),     #roams_obs_var = map_dbl(roams, ~ sum(.$par[4:5])),     #roams_state_var = map_dbl(roams, ~ sum(.$par[2:3])),          roams_MSFE = map2_dbl(       roams_oos, y_oos,       function(roams_oos, y_oos) {         SFEs = rowSums((y_oos - roams_oos$predicted_observations)^2)         MSFE = mean(SFEs, na.rm = TRUE)         return(MSFE)       }     ),     classical_MSFE = map2_dbl(       classical_oos, y_oos,       function(classical_oos, y_oos) {         SFEs = rowSums((y_oos - classical_oos$predicted_observations)^2)         MSFE = mean(SFEs, na.rm = TRUE)         return(MSFE)       }     ),               roams_trimmed_MSFE_5perc = map2_dbl(       roams_oos, y_oos,       function(roams_oos, y_oos) {         SFEs = rowSums((y_oos - roams_oos$predicted_observations)^2)         num_trim = round(0.05 * length(SFEs))         ascending_SFEs = sort(na.omit(SFEs))         n_complete = length(ascending_SFEs)         trimmed_SFEs = ascending_SFEs[1:(n_complete - num_trim)]         trimmed_MSFE = mean(trimmed_SFEs)         return(trimmed_MSFE)       }     ),     classical_trimmed_MSFE_5perc = map2_dbl(       classical_oos, y_oos,       function(classical_oos, y_oos) {         SFEs = rowSums((y_oos - classical_oos$predicted_observations)^2)         num_trim = round(0.05 * length(SFEs))         ascending_SFEs = sort(na.omit(SFEs))         n_complete = length(ascending_SFEs)         trimmed_SFEs = ascending_SFEs[1:(n_complete - num_trim)]         trimmed_MSFE = mean(trimmed_SFEs)         return(trimmed_MSFE)       }     ),     roams_trimmed_MSFE_10perc = map2_dbl(       roams_oos, y_oos,       function(roams_oos, y_oos) {         SFEs = rowSums((y_oos - roams_oos$predicted_observations)^2)         num_trim = round(0.1 * length(SFEs))         ascending_SFEs = sort(na.omit(SFEs))         n_complete = length(ascending_SFEs)         trimmed_SFEs = ascending_SFEs[1:(n_complete - num_trim)]         trimmed_MSFE = mean(trimmed_SFEs)         return(trimmed_MSFE)       }     ),     classical_trimmed_MSFE_10perc = map2_dbl(       classical_oos, y_oos,       function(classical_oos, y_oos) {         SFEs = rowSums((y_oos - classical_oos$predicted_observations)^2)         num_trim = round(0.1 * length(SFEs))         ascending_SFEs = sort(na.omit(SFEs))         n_complete = length(ascending_SFEs)         trimmed_SFEs = ascending_SFEs[1:(n_complete - num_trim)]         trimmed_MSFE = mean(trimmed_SFEs)         return(trimmed_MSFE)       }     ),               roams_MSFE_clean = map2_dbl(       roams_oos, y_oos,       function(roams_oos, y_oos) {         clean_timepoints = which(roams_oos$outliers_flagged == 0)         SFEs = rowSums((y_oos - roams_oos$predicted_observations)^2)         MSFE_clean = mean(SFEs[clean_timepoints], na.rm = TRUE)         return(MSFE_clean)       }     ),     classical_MSFE_clean = pmap_dbl(       list(classical_oos, roams_oos, y_oos),       function(classical_oos, roams_oos, y_oos) {         clean_timepoints = which(roams_oos$outliers_flagged == 0)         SFEs = rowSums((y_oos - classical_oos$predicted_observations)^2)         MSFE_clean = mean(SFEs[clean_timepoints], na.rm = TRUE)         return(MSFE_clean)       }     )               # roams_MedSFE = map2_dbl(     #   roams_oos, y_oos,     #   ~ median(rowSums((.y - .x$predicted_observations)^2),      #            na.rm = TRUE)     # ),     # classical_MedSFE = map2_dbl(     #   classical_oos, y_oos,     #   ~ median(rowSums((.y - .x$predicted_observations)^2),      #            na.rm = TRUE)     # )          )  %>%    select(name, frequency, n, n_complete, n_oos, n_oos_complete,          in_sample_detected, oos_detected, roams_phi, classical_phi,          roams_MSFE:classical_MSFE_clean) %>%    knitr::kable()"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"plot-out-of-sample-squared-forecast-errors","dir":"Articles","previous_headings":"Results","what":"Plot out-of-sample squared forecast errors","title":"DCRW examples","text":"","code":"results %>%    mutate(     classical_SFEs = map2(       classical_oos, y_oos,        function(classical_oos, y_oos) {         SFEs = rowSums((y_oos - classical_oos$predicted_observations)^2)         SFEs = na.omit(SFEs)         return(SFEs)       }     ),     roams_SFEs = map2(       roams_oos, y_oos,        function(roams_oos, y_oos) {         SFEs = rowSums((y_oos - roams_oos$predicted_observations)^2)         SFEs = na.omit(SFEs)         return(SFEs)       }     )   ) %>%    select(name, classical_SFEs, roams_SFEs) %>%    pivot_longer(c(classical_SFEs, roams_SFEs),                 names_to = \"method\", values_to = \"SFE\") %>%    mutate(method = stringr::word(method, start = 1, end = 1, sep = \"_\")) %>%    unnest_longer(SFE) %>%    ggplot() +   aes(x = method, y = SFE, colour = name) +   geom_boxplot() +   facet_wrap(~ name, scales = \"free\") +   theme_bw() +   theme(legend.position = \"none\")"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"plot-in-sample-fit","dir":"Articles","previous_headings":"Results","what":"Plot in-sample fit","title":"DCRW examples","text":"","code":"plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- max(diff(y_range) - diff(x_range), 0) / 2  + diff(x_range) * 0.05   y_pad <- max(diff(x_range) - diff(y_range), 0) / 6  + diff(y_range) * 0.05      result = results %>%      slice(i)      fitted_paths = tibble(     x_roams = result$roams[[1]]$smoothed_observations[,1],     y_roams = result$roams[[1]]$smoothed_observations[,2],     x_classical = result$classical[[1]]$smoothed_observations[,1],     y_classical = result$classical[[1]]$smoothed_observations[,2]   )    detected_outliers = which(rowSums(abs(result$roams[[1]]$gamma)) != 0)      plots[[i]] = data_sets[[i]] %>%      # Retain in-sample data points     slice(1:round(0.9*n())) %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_point(aes(x = x, y = y), alpha = 0.3) +     geom_path(data = fitted_paths,               aes(x = x_classical,                   y = y_classical), colour = \"royalblue\") +     geom_path(data = fitted_paths,               aes(x = x_roams,                   y = y_roams), colour = \"orange\") +     geom_point(data = data_sets[[i]] %>%                   slice(1:round(0.9*n())) %>%                   slice(detected_outliers),                aes(x = x, y = y),                 colour = \"orange\", size = 2, stroke = 1, pch = 1) +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3)"},{"path":"https://github.com/rajan-shankar/roams/articles/dcrw_examples.html","id":"plot-one-step-ahead-out-of-sample-predictions","dir":"Articles","previous_headings":"Results","what":"Plot one-step-ahead out-of-sample predictions","title":"DCRW examples","text":"","code":"plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- max(diff(y_range) - diff(x_range), 0) / 2  + diff(x_range) * 0.05   y_pad <- max(diff(x_range) - diff(y_range), 0) / 6  + diff(y_range) * 0.05      result = results %>%      slice(i)      oos_paths = tibble(     x_roams = result$roams_oos[[1]]$predicted_observations[,1],     y_roams = result$roams_oos[[1]]$predicted_observations[,2],     x_classical = result$classical_oos[[1]]$predicted_observations[,1],     y_classical = result$classical_oos[[1]]$predicted_observations[,2]   )      detected_outliers = which(result$roams_oos[[1]]$outliers_flagged == 1)      plots[[i]] = data_sets[[i]] %>%      # Retain in-sample data points     slice((round(0.9*n()) + 1) : n()) %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_point(aes(x = x, y = y), alpha = 0.3) +     geom_path(data = oos_paths,               aes(x = x_classical,                   y = y_classical), colour = \"royalblue\") +     geom_path(data = oos_paths,               aes(x = x_roams,                   y = y_roams), colour = \"orange\") +     geom_point(data = data_sets[[i]] %>%                   slice((round(0.9*n()) + 1) : n()) %>%                   slice(detected_outliers),                aes(x = x, y = y),                 colour = \"orange\", size = 2, stroke = 1, pch = 1) +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3)"},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"blue-whale-2008","dir":"Articles","previous_headings":"","what":"Blue whale (2008)","title":"DCRW examples","text":"Plot world map data:","code":"whale_2008 = read_csv(\"data/Blue whales Eastern North Pacific 1993-2008 - Argos Data.csv\") |>   # Standardise column names   janitor::clean_names() |>     # Keep only rows for the whale with ID \"2008CA-Bmu-10839\"   filter(individual_local_identifier == \"2008CA-Bmu-10839\") |>    # Replace missing values in 'manually_marked_outlier' with FALSE   mutate(manually_marked_outlier = tidyr::replace_na(manually_marked_outlier, FALSE)) |>    # Round timestamps to the nearest 12 hours   mutate(timestamp = lubridate::round_date(timestamp, \"12 hours\")) |>    # Within each group, keep only the last row (e.g. latest observation per 12-hour block)   group_by(timestamp) |>    slice_tail(n = 1) |>    # Convert the data to a tsibble object (time series tibble)   tsibble::tsibble() |>   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() |>    # Convert back to a regular tibble   as_tibble() |>    # Rename longitude/latitude columns to x and y   rename(x = location_long,          y = location_lat) library(rnaturalearth) library(rnaturalearthdata) #>  #> Attaching package: 'rnaturalearthdata' #> The following object is masked from 'package:rnaturalearth': #>  #>     countries110 library(sf) #> Linking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE  # Get country boundaries as an sf object world <- ne_countries(scale = \"medium\", returnclass = \"sf\")  # Work out x/y ranges with some padding x_range <- range(whale_2008$x, na.rm = TRUE) y_range <- range(whale_2008$y, na.rm = TRUE)  x_pad <- diff(x_range) * 0.05  # 5% padding y_pad <- diff(y_range) * 0.05 # 5% padding  whale_2008 %>%    ggplot() +   # Country boundaries   geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +      # Whale track and points   geom_path(aes(x = x, y = y, colour = timestamp), alpha = 0.2) +   geom_point(aes(x = x, y = y, colour = timestamp)) +      # Colour scale   viridis::scale_color_viridis() +      # Focus map on whale’s range   coord_sf(     xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),     ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),     expand = FALSE   ) +      # Labels and theme   labs(x = \"Longitude\", y = \"Latitude\", subtitle = \"whale_2008\") +   theme_minimal() +   theme(legend.position = \"none\") #> Warning: Removed 21 rows containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"polar-bear","dir":"Articles","previous_headings":"","what":"Polar bear","title":"DCRW examples","text":"","code":"polar_low_freq = read_csv(\"data/PB_Argos.csv\") %>%    # Standardise column names   clean_names() %>%    # Convert date_time column to a proper datetime object called 'timestamp'   mutate(timestamp = ymd_hms(date_time)) %>%    # Drop the original date_time column   select(-date_time) %>%    # Round timestamps to the nearest day   mutate(timestamp = lubridate::round_date(timestamp, \"1 day\")) %>%    # Within each group, keep only the first row (e.g. earliest observation per day)   group_by(timestamp) %>%    slice_head(n = 1) %>%    # Convert timestamp to a Date object (drop time-of-day information)   mutate(timestamp = as.Date(timestamp)) %>%    # Convert the data to a tsibble object (time series tibble)   tsibble::tsibble() %>%   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() %>%   # Convert back to a regular tibble   as_tibble() %>%    # Rename longitude/latitude columns to x and y   rename(x = lon,          y = lat) #> Rows: 1919 Columns: 4 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (2): DateTime, QualClass #> dbl (2): Lat, Lon #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Using `timestamp` as index variable."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"seal","dir":"Articles","previous_headings":"","what":"Seal","title":"DCRW examples","text":"","code":"seal = read_csv(\"data/sealLocs.csv\") %>%    # Keep only rows for the seal with ID \"stephanie\"   filter(id == \"stephanie\") %>%    # Round timestamps to the nearest day   mutate(timestamp = lubridate::round_date(time, \"1 day\")) %>%    # Within each group, keep only the last row (e.g. latest observation per day)   group_by(timestamp) %>%    slice_tail(n = 1) %>%    # Convert timestamp to a Date object (drop time-of-day information)   mutate(timestamp = as.Date(timestamp)) %>%    # Convert the data to a tsibble object indexed by timestamp   tsibble::tsibble(index = timestamp) %>%   # Fill in missing time points in the series with explicit gaps   tsibble::fill_gaps() %>%   # Convert back to a regular tibble   as_tibble() %>%    # Rename longitude/latitude columns to x and y   rename(x = lon,          y = lat) #> Rows: 369 Columns: 5 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (2): id, class #> dbl  (2): lon, lat #> dttm (1): time #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"cats","dir":"Articles","previous_headings":"","what":"Cats","title":"DCRW examples","text":"","code":"cat_mia = read_csv(\"data/Feral cat (Felis catus) - Scotia, NSW.csv\") %>%    clean_names() %>%    mutate(algorithm_marked_outlier = ifelse(is.na(algorithm_marked_outlier),                                                   FALSE,                                                  algorithm_marked_outlier),          manually_marked_outlier = ifelse(is.na(manually_marked_outlier),                                                   FALSE,                                                  manually_marked_outlier),          outlier = algorithm_marked_outlier | manually_marked_outlier) %>%    filter(individual_local_identifier == \"Mia_FC642\") %>%    mutate(timestamp = lubridate::round_date(timestamp, \"20 minutes\")) %>%    tsibble::tsibble() %>%   tsibble::fill_gaps() %>%    slice(-(1:19)) %>%    as_tibble() %>%    rename(x = location_long,          y = location_lat) #> Rows: 112744 Columns: 19 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr   (5): sensor-type, individual-taxon-canonical-name, tag-local-identifie... #> dbl  (10): event-id, location-long, location-lat, external-temperature, gps:... #> lgl   (3): visible, algorithm-marked-outlier, manually-marked-outlier #> dttm  (1): timestamp #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Using `timestamp` as index variable.  cat_max = read_csv(\"data/Feral cat (Felis catus) - Scotia, NSW.csv\") %>%    clean_names() %>%    mutate(algorithm_marked_outlier = ifelse(is.na(algorithm_marked_outlier),                                                   FALSE,                                                  algorithm_marked_outlier),          manually_marked_outlier = ifelse(is.na(manually_marked_outlier),                                                   FALSE,                                                  manually_marked_outlier),          outlier = algorithm_marked_outlier | manually_marked_outlier) %>%    filter(individual_local_identifier == \"Max_MC629\") %>%    mutate(timestamp = lubridate::round_date(timestamp, \"20 minutes\")) %>%    tsibble::tsibble() %>%   tsibble::fill_gaps() %>%    slice(-(1:24)) %>%    as_tibble() %>%    rename(x = location_long,          y = location_lat) #> Rows: 112744 Columns: 19 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr   (5): sensor-type, individual-taxon-canonical-name, tag-local-identifie... #> dbl  (10): event-id, location-long, location-lat, external-temperature, gps:... #> lgl   (3): visible, algorithm-marked-outlier, manually-marked-outlier #> dttm  (1): timestamp #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Using `timestamp` as index variable."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"cows","dir":"Articles","previous_headings":"","what":"Cows","title":"DCRW examples","text":"","code":"cow = read_csv(\"data/export_UQ_GPS.csv\") %>%    clean_names() %>%    filter(partition_key == \"70741400000EB036\") %>%    rename(x_metres = longitude,          y_metres = latitude) %>%    mutate(date = date(timestamp)) %>%    select(date, timestamp, x_metres, y_metres) %>%   group_by(date) %>%    mutate(diff = c(2.38, diff(timestamp))) %>%   mutate(missing_rows = map(diff, ~ seq_len(round(. / 2.38)))) %>%   unnest(missing_rows) %>%   mutate(x_metres = ifelse(missing_rows > 1, NA, x_metres),          y_metres = ifelse(missing_rows > 1, NA, y_metres)) %>%    ungroup() %>%    rename(x = x_metres,          y = y_metres) #> New names: #> Rows: 95466 Columns: 17 #> ── Column specification #> ──────────────────────────────────────────────────────── Delimiter: \",\" chr #> (4): PartitionKey, RowKey, MessageType, TagId dbl (11): ...1, Temperature, #> BatteryVoltage, StdDevAccelerationX, StdDevAcc... dttm (2): Timestamp, #> EventDate #> ℹ Use `spec()` to retrieve the full column specification for this data. ℹ #> Specify the column types or set `show_col_types = FALSE` to quiet this message. #> • `` -> `...1`  cow_10 = cow %>% filter(date == \"2024-11-10\") cow_11 = cow %>% filter(date == \"2024-11-11\") cow_12 = cow %>% filter(date == \"2024-11-12\")"},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"collate-data-sets-into-a-list","dir":"Articles","previous_headings":"","what":"Collate data sets into a list","title":"DCRW examples","text":"","code":"data_sets = list(   \"cat_max\" = cat_max,   \"cat_mia\" = cat_mia,   \"cow_10\" = cow_10,   \"cow_11\" = cow_11,   \"cow_12\" = cow_12,   \"polar_low_freq\" = polar_low_freq,   \"seal\" = seal,   # \"whale_1994\" = whale_1994,   # \"whale_1995\" = whale_1995,   \"whale_2008\" = whale_2008 )"},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"summary-of-missingness-proportion-and-size-of-data-sets","dir":"Articles","previous_headings":"","what":"Summary of missingness proportion and size of data sets","title":"DCRW examples","text":"","code":"data_sets %>%    map_dbl(~ mean(is.na(.$x))) %>%    round(2) %>%    as_tibble(rownames = \"data_set\") %>%    rename(proportion_missing = value) %>%    mutate(n = data_sets %>% map_dbl(~ length(.$x))) %>%    arrange(data_set) %>%    knitr::kable()"},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"plot-data-sets-on-world-map","dir":"Articles","previous_headings":"","what":"Plot data sets on world map","title":"DCRW examples","text":"","code":"# Get country boundaries as an sf object world <- ne_countries(scale = \"medium\", returnclass = \"sf\")  plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- diff(x_range) * 0.05  # 5% padding   y_pad <- diff(y_range) * 0.05 # 5% padding    plots[[i]] = data_sets[[i]] %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_path(aes(x = x, y = y, colour = timestamp), alpha = 0.2) +     geom_point(aes(x = x, y = y, colour = timestamp)) +          # Colour scale     viridis::scale_color_viridis() +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3) #> Warning: Removed 252 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 93 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 56 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 44 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 41 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 34 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 7 rows containing missing values or values outside the scale range #> (`geom_path()`). #> Warning: Removed 36 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 21 rows containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"fit-models-using-roams-and-classical-methods","dir":"Articles","previous_headings":"","what":"Fit models using ROAMS and classical methods","title":"DCRW examples","text":"last 20 points data set left use ‘test set’ later .","code":"results = read_rds(\"data/results.rds\") results = tibble(   name = character(),   data_set = list(),   y = list(),   y_oos = list(),   classical = list(),   roams = list(),   classical_oos = list(),   roams_oos = list() )  for (i in 1:length(data_sets)) {      y_all = data_sets[[i]] %>%      select(x, y) %>%      as.matrix()      n = nrow(y_all)   y = y_all[1:(n-20),]   y_oos = y_all[(n-20+1):n,]      var_est = c(mad(diff(y[,1]), na.rm = TRUE)^2,               mad(diff(y[,2]), na.rm = TRUE)^2)      build_fn = function(parm) {          phi_coef = parm[1]     Phi = diag(c(1+phi_coef, 1+phi_coef, 0, 0))     Phi[1,3] = -phi_coef     Phi[2,4] = -phi_coef     Phi[3,1] = 1     Phi[4,2] = 1          A = diag(4)[1:2,]     Q = diag(c(parm[2], parm[3], 0, 0))     R = diag(c(parm[4], parm[5]))          x0 = c(y[1,], y[1,])     P0 = diag(rep(0, 4))          specify_SSM(       state_transition_matrix = Phi,       state_noise_var = Q,       observation_matrix = A,       observation_noise_var = R,       init_state_mean = x0,       init_state_var = P0)   }      model_classical = classical_SSM(     y = y,      init_par = c(0.5, var_est, var_est),      build = build_fn,      lower = c(0, rep(1e-12, 4)),     upper = c(1, rep(Inf, 4)),     )      model_roams = robularized_SSM(     y = y,     init_par = c(0.5, var_est, var_est),     build = build_fn,     num_lambdas = 20,     cores = 4,     lower = c(0, rep(1e-12, 4)),     upper = c(1, rep(Inf, 4)),     B = 50     )      model_classical = attach_insample_info(model_classical)      model_roams_best = best_BIC_model(model_roams)   model_roams_best = attach_insample_info(model_roams_best)      # Out-of-sample metrics      # Re-create build function with different initial state mean   build_oos_fn = function(par) {      phi_coef = par[1]     Phi = diag(c(1+phi_coef, 1+phi_coef, 0, 0))     Phi[1,3] = -phi_coef     Phi[2,4] = -phi_coef     Phi[3,1] = 1     Phi[4,2] = 1      A = diag(4)[1:2,]     Q = diag(c(par[2], par[3], 0, 0))     R = diag(c(par[4], par[5]))          # Some data sets have first few out-of-sample timepoints missing, so get use first non-missing timepoint to initialise     first_complete_obs = which(!is.na(y_oos[,1]))[1]     x0_oos = c(y_oos[first_complete_obs,],                 y_oos[first_complete_obs,])     P0 = diag(rep(0, 4))      specify_SSM(       state_transition_matrix = Phi,       state_noise_var = Q,       observation_matrix = A,       observation_noise_var = R,       init_state_mean = x0_oos,       init_state_var = P0)   }      classical_oos = oos_filter(     y_oos = y_oos,      model = model_classical,      build = build_oos_fn)      roams_oos = oos_filter(     y_oos = y_oos,      model = model_roams_best,      build = build_oos_fn)      results = results %>%      add_row(       name = names(data_sets)[i],       data_set = list(data_sets[[i]]),       y = list(y),       y_oos = list(y_oos),       classical = list(model_classical),       roams = list(model_roams_best),       classical_oos = list(classical_oos),       roams_oos = list(roams_oos)     )      cat(\"Data set\", i, \"complete\\n\") }  # readr::write_rds(results, \"vignettes/data/results.rds\")"},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"compute-and-summarise-results","dir":"Articles","previous_headings":"","what":"Compute and summarise results","title":"DCRW examples","text":"","code":"results %>%    mutate(     n = map_dbl(y, ~ nrow(.)),     n_complete = map_dbl(y, ~ sum(!is.na(.[,1]))),     n_oos = 20,     n_oos_complete = map_dbl(y_oos, ~ sum(!is.na(.[,1]))),          in_sample_detected = map2_dbl(roams, n_complete,                                   ~ .x$prop_outlying * .y),     oos_detected = map_dbl(roams_oos,                            ~ sum(.$outliers_flagged)),          classical_phi = map_dbl(classical, ~ .$par[1]),     roams_phi = map_dbl(roams, ~ .$par[1]),     roams_obs_var = map_dbl(roams, ~ sum(.$par[4:5])),     roams_state_var = map_dbl(roams, ~ sum(.$par[2:3])),          classical_MSFE = map2_dbl(       classical_oos, y_oos,       ~ mean(rowSums((.y - .x$predicted_observations)^2),               na.rm = TRUE)),     roams_MSFE = map2_dbl(       roams_oos, y_oos,       ~ mean(rowSums((.y - .x$predicted_observations)^2),               na.rm = TRUE)),     classical_MedSFE = map2_dbl(       classical_oos, y_oos,       ~ median(rowSums((.y - .x$predicted_observations)^2),                 na.rm = TRUE)),     roams_MedSFE = map2_dbl(       roams_oos, y_oos,       ~ median(rowSums((.y - .x$predicted_observations)^2),                 na.rm = TRUE))     )  %>%    select(name, n, n_complete, n_oos, n_oos_complete, in_sample_detected, oos_detected, roams_phi, classical_phi, roams_MSFE, classical_MSFE, roams_MedSFE, classical_MedSFE, roams_obs_var, roams_state_var) %>%    knitr::kable()"},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"plot-in-sample-fit","dir":"Articles","previous_headings":"","what":"Plot in-sample fit","title":"DCRW examples","text":"","code":"plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- diff(x_range) * 0.05  # 5% padding   y_pad <- diff(y_range) * 0.05  # 5% padding      result = results %>%      slice(i)      fitted_paths = tibble(     x_roams = result$roams[[1]]$smoothed_observations[,1],     y_roams = result$roams[[1]]$smoothed_observations[,2],     x_classical = result$classical[[1]]$smoothed_observations[,1],     y_classical = result$classical[[1]]$smoothed_observations[,2]   )    detected_outliers = which(rowSums(abs(result$roams[[1]]$gamma)) != 0)      plots[[i]] = data_sets[[i]] %>%      # Retain in-sample data points     slice(1:(n() - 20)) %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_point(aes(x = x, y = y)) +     geom_path(data = fitted_paths,               aes(x = x_classical,                   y = y_classical), colour = \"royalblue\") +     geom_path(data = fitted_paths,               aes(x = x_roams,                   y = y_roams), colour = \"orange\") +     geom_point(data = data_sets[[i]] %>%                   slice(1:(n() - 20)) %>%                   slice(detected_outliers),                aes(x = x, y = y),                 colour = \"orange\", size = 2, stroke = 1, pch = 1) +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3) #> Warning: Removed 241 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 85 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 55 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 44 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 38 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 28 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 22 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 20 rows containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":"https://github.com/rajan-shankar/roams/articles/examples.html","id":"plot-one-step-ahead-out-of-sample-predictions","dir":"Articles","previous_headings":"","what":"Plot one-step-ahead out-of-sample predictions","title":"DCRW examples","text":"","code":"plots = list() for (i in 1:length(data_sets)) {   # Work out x/y ranges with some padding   x_range <- range(data_sets[[i]]$x, na.rm = TRUE)   y_range <- range(data_sets[[i]]$y, na.rm = TRUE)      x_pad <- diff(x_range) * 0.05  # 5% padding   y_pad <- diff(y_range) * 0.05  # 5% padding      result = results %>%      slice(i)      oos_paths = tibble(     x_roams = result$roams_oos[[1]]$predicted_observations[,1],     y_roams = result$roams_oos[[1]]$predicted_observations[,2],     x_classical = result$classical_oos[[1]]$predicted_observations[,1],     y_classical = result$classical_oos[[1]]$predicted_observations[,2]   )      detected_outliers = which(result$roams_oos[[1]]$outliers_flagged == 1)      plots[[i]] = data_sets[[i]] %>%      # Retain in-sample data points     slice((n() - 20 + 1) : n()) %>%      ggplot() +     # Country boundaries     geom_sf(data = world, fill = \"grey95\", colour = \"grey70\", size = 0.3) +          # Animal path and points     geom_point(aes(x = x, y = y)) +     geom_path(data = oos_paths,               aes(x = x_classical,                   y = y_classical), colour = \"royalblue\") +     geom_path(data = oos_paths,               aes(x = x_roams,                   y = y_roams), colour = \"orange\") +     geom_point(data = data_sets[[i]] %>%                   slice((n() - 20 + 1) : n()) %>%                   slice(detected_outliers),                aes(x = x, y = y),                 colour = \"orange\", size = 2, stroke = 1, pch = 1) +          # Focus map on animal’s range     coord_sf(       xlim = c(x_range[1] - x_pad, x_range[2] + x_pad),       ylim = c(y_range[1] - y_pad, y_range[2] + y_pad),       expand = FALSE     ) +          # Labels and theme     labs(x = \"Longitude\", y = \"Latitude\", subtitle = names(data_sets)[i]) +     theme_minimal() +     theme(legend.position = \"none\") }  wrap_plots(plots) + plot_layout(ncol = 3) #> Warning: Removed 11 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_point()`). #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning in st_is_longlat(x): bounding box has potentially an invalid value #> range for longlat data #> Warning: Removed 3 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 6 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 14 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":[]},{"path":[]},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rajan Shankar. Author, maintainer. Garth Tarr. Author. Ines Wilms. Author. Jakob Raymaekers. Author.","code":""},{"path":"https://github.com/rajan-shankar/roams/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Shankar R, Tarr G, Wilms , Raymaekers J (2025). roams: Robust Outlier-Adjusted Mean-Shift Estimation State-Space Models. R package version 0.3.1, https://github.com/rajan-shankar/roams.","code":"@Manual{,   title = {roams: Robust Outlier-Adjusted Mean-Shift Estimation of State-Space Models},   author = {Rajan Shankar and Garth Tarr and Ines Wilms and Jakob Raymaekers},   year = {2025},   note = {R package version 0.3.1},   url = {https://github.com/rajan-shankar/roams}, }"},{"path":"https://github.com/rajan-shankar/roams/index.html","id":"roams","dir":"","previous_headings":"","what":"Robust Outlier-Adjusted Mean-Shift Estimation of State-Space Models","title":"Robust Outlier-Adjusted Mean-Shift Estimation of State-Space Models","text":"goal roams provide methods robust estimation outlier detection state-space models. includes functionality fitting benchmark models, visualizing model selection criteria, evaluating -sample --sample performance. Simulation tools generating synthetic data first-difference correlated random walk (DCRW) model also included. Designed flexibility user-defined model structures via specify_SSM() interface.","code":""},{"path":"https://github.com/rajan-shankar/roams/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Robust Outlier-Adjusted Mean-Shift Estimation of State-Space Models","text":"can install development version roams GitHub :","code":"# install.packages(\"pak\") pak::pak(\"rajan-shankar/roams\")"},{"path":"https://github.com/rajan-shankar/roams/reference/attach_insample_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","title":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","text":"Attaches detailed -sample information—predicted, filtered, smoothed states observations—model object fitted using package’s supported SSM estimation methods. quantities stored default model objects due potentially large memory footprint.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/attach_insample_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","text":"","code":"attach_insample_info(model)"},{"path":"https://github.com/rajan-shankar/roams/reference/attach_insample_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","text":"model fitted model object class robularized_SSM, classical_SSM, oracle_SSM, huber_robust_SSM, trimmed_robust_SSM.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/attach_insample_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","text":"modified version input model object, additional class insample_info, following -sample elements appended: filtered_states Filtered state estimates using data time point. predicted_states One-step-ahead state predictions. filtered_observations Expected observations given data time point. predicted_observations One-step-ahead forecasts observations. filtered_states_var List filtered state variance matrices. predicted_states_var List one-step-ahead state prediction variances. predicted_observations_var List one-step-ahead observation forecast variances. mahalanobis_residuals Vector Mahalanobis distances residuals predicted observations. models class robularized_SSM, classical_SSM, oracle_SSM, following additional elements also attached: smoothed_states Posterior means hidden states using data. smoothed_observations Posterior mean observed series based smoothed states. smoothed_states_var List smoothed state variance matrices.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/attach_insample_info.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Attach In-Sample Information to Fitted State Space Model — attach_insample_info","text":"attached outputs enable richer diagnostics, outlier inspection, plotting. huber_robust_SSM trimmed_robust_SSM models, -sample information computed using custom robust filtering function, smoothed quantities (smoothed_states, smoothed_observations, smoothed_states_var) available. function applied model object.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/autoplot.robularized_SSM_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","title":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","text":"Generates diagnostic plots list robust state space models fit across sequence \\(\\lambda\\) values. Two model attributes plotted \\(\\lambda\\), panel, vertical dashed line indicating model lowest BIC among fewer 50% outliers.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/autoplot.robularized_SSM_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","text":"","code":"# S3 method for class 'robularized_SSM_list' autoplot(object, attribute1 = \"BIC\", attribute2 = \"prop_outlying\", ...)"},{"path":"https://github.com/rajan-shankar/roams/reference/autoplot.robularized_SSM_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","text":"object object class robularized_SSM_list returned robularized_SSM multiple \\(\\lambda\\) values used. attribute1 character string indicating first model attribute plot top panel. Options include \"lambda\", \"prop_outlying\", \"BIC\", \"loglik\", \"RSS\", \"iterations\", \"value\", \"counts\". Defaults \"BIC\". attribute2 character string indicating second model attribute plot bottom panel. Uses options attribute1. Defaults \"prop_outlying\". ... arguments passed specific methods. used method.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/autoplot.robularized_SSM_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","text":"ggplot object arranged using patchwork package, showing specified attributes plotted \\(\\lambda\\) two vertically stacked panels.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/autoplot.robularized_SSM_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autoplot for Robularized State Space Model List — autoplot.robularized_SSM_list","text":"panel, red dashed vertical line indicates model lowest BIC among fewer 50% outlying time points, serving heuristic robust model selection.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/best_BIC_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Best Model Based on BIC — best_BIC_model","title":"Select Best Model Based on BIC — best_BIC_model","text":"Extracts best-fitting model robularized_SSM_list object according Bayesian Information Criterion (BIC), excluding models 50% outlying observations.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/best_BIC_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Best Model Based on BIC — best_BIC_model","text":"","code":"best_BIC_model(model_list)"},{"path":"https://github.com/rajan-shankar/roams/reference/best_BIC_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Best Model Based on BIC — best_BIC_model","text":"model_list object class robularized_SSM_list","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/best_BIC_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Best Model Based on BIC — best_BIC_model","text":"single robularized_SSM object corresponding model smallest BIC among fewer 50% outlying observations.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/best_BIC_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Best Model Based on BIC — best_BIC_model","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming `models` is a robularized_SSM_list: best_model <- best_BIC_model(models) } # }"},{"path":"https://github.com/rajan-shankar/roams/reference/classical_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Classical State Space Model Fit — classical_SSM","title":"Classical State Space Model Fit — classical_SSM","text":"Fits state space model using classical maximum likelihood estimation attempt detect account outliers. serves baseline model comparison.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/classical_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classical State Space Model Fit — classical_SSM","text":"","code":"classical_SSM(   y,   init_par,   build,   lower = NA,   upper = NA,   control = list(parscale = init_par) )"},{"path":"https://github.com/rajan-shankar/roams/reference/classical_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classical State Space Model Fit — classical_SSM","text":"y numeric matrix observations (time points rows). init_par numeric vector initial parameter values. build function returns dlm model given parameter vector. specify_SSM() function can used create build function. lower Optional numeric vector lower bounds parameter estimation. Defaults -Inf. Must length init_par. upper Optional numeric vector upper bounds parameter estimation. Defaults Inf. Must length init_par. control Optional list control parameters passed optim via dlm::dlmMLE(). Default list(parscale = init_par), can help optimizer parameters vastly different scales.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/classical_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classical State Space Model Fit — classical_SSM","text":"object class classical_SSM containing optimization result, original data, original build function.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/get_attribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Attributes from a Robularized SSM List — get_attribute","title":"Extract Attributes from a Robularized SSM List — get_attribute","text":"Retrieves specified attribute model within robularized_SSM_list object. Also works single model class robularized_SSM provided.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/get_attribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Attributes from a Robularized SSM List — get_attribute","text":"","code":"get_attribute(model_list, attribute)"},{"path":"https://github.com/rajan-shankar/roams/reference/get_attribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Attributes from a Robularized SSM List — get_attribute","text":"model_list object class robularized_SSM_list single robularized_SSM model. May optionally include -sample information added via attach_insample_info. attribute character string specifying name attribute extract. Must one available scalar attributes (e.g. BIC, lambda) list/vector attributes (e.g. filtered_states, smoothed_states).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/get_attribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Attributes from a Robularized SSM List — get_attribute","text":"attribute scalar attribute (e.g., BIC lambda), returns numeric character vector containing attribute across models. attribute list-like attribute (e.g., par gamma), returns list values, across models.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/get_attribute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Attributes from a Robularized SSM List — get_attribute","text":"Available attributes depend whether -sample information attached using attach_insample_info(). , core model components (e.g. par, gamma, y) scalar metrics (e.g. BIC, loglik) available. Scalar Attributes (always available): lambda: Regularization penalty value. prop_outlying: Proportion outlying time points identified. BIC: Bayesian Information Criterion. loglik: Log-likelihood. RSS: Residual sum squares. iterations: Number IPOD iterations. value: Final objective function value. convergence: Convergence status optimizer. message: Optimizer termination message. List/Vector Attributes always available: par, gamma, y, counts List/Vector Attributes available -sample info attached: smoothed_states, filtered_states, predicted_states smoothed_observations, filtered_observations, predicted_observations smoothed_states_var, filtered_states_var, predicted_states_var, predicted_observations_var mahalanobis_residuals Note '-sample info' attributes typically available model_list single robularized_SSM -sample information already attached using attach_insample_info(). model_list robularized_SSM_list, attributes available unless models list -sample information attached.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/huber_robust_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Huber-Robust State Space Model Fit — huber_robust_SSM","title":"Huber-Robust State Space Model Fit — huber_robust_SSM","text":"Fits robust state space model minimizing Huber loss objective per Crevits Croux (2018), providing protection moderate outliers. predicted observations used Huber loss computed using Huber robust filter Cipra Romera (1997).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/huber_robust_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Huber-Robust State Space Model Fit — huber_robust_SSM","text":"","code":"huber_robust_SSM(   y,   init_par,   build,   lower = NA,   upper = NA,   control = list(parscale = init_par) )"},{"path":"https://github.com/rajan-shankar/roams/reference/huber_robust_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Huber-Robust State Space Model Fit — huber_robust_SSM","text":"y numeric matrix observations (time points rows). init_par numeric vector initial parameter values. build function returns dlm model given parameter vector. specify_SSM() function can used create build function. lower Optional numeric vector lower bounds parameter estimation. Defaults -Inf. Must length init_par. upper Optional numeric vector upper bounds parameter estimation. Defaults Inf. Must length init_par. control Optional list control parameters passed optim. Default list(parscale = init_par), can help optimizer parameters vastly different scales.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/huber_robust_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Huber-Robust State Space Model Fit — huber_robust_SSM","text":"object class huber_robust_SSM containing optimization result, original data, original build function.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/huber_robust_SSM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Huber-Robust State Space Model Fit — huber_robust_SSM","text":"Crevits R. Croux C. (2018). Robust Estimation Linear State Space Models. *Communications Statistics: Simulation Computation* Cipra, T., Romera, R. (1997). Kalman filter outliers missing observations. *Test* 6, 379–395. https://doi.org/10.1007/BF02564705","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/oos_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","title":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","text":"Applies fitted model parameters user-supplied --sample dataset compute predicted filtered states observations. Robust classical inference procedures supported depending class input model.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/oos_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","text":"","code":"oos_filter(   y_oos,   model,   build,   outlier_locs = rep(0, nrow(y_oos)),   threshold = sqrt(qchisq(0.99, ncol(y_oos))),   multiplier = 2 )"},{"path":"https://github.com/rajan-shankar/roams/reference/oos_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","text":"y_oos numeric matrix containing --sample observations. row corresponds time point. model fitted model object class robularized_SSM, classical_SSM, oracle_SSM, huber_robust_SSM, trimmed_robust_SSM. build function maps numeric parameter vector corresponding dlm model object. specify_SSM function can used create build function. outlier_locs logical binary vector length nrow(y), indicating time points treated missing (.e., time points known outliers). Used oracle_SSM models. threshold Mahalanobis distance threshold identifying outliers robularized_SSM models. Default sqrt(qchisq(0.99, ncol(y))). multiplier Multiplier quickly filter grows filtered state variance (uncertainty) detecting outlier robularized_SSM models. Default 2.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/oos_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","text":"named list containing --sample inference results: filtered_states Filtered state estimates using --sample data. predicted_states One-step-ahead state predictions. filtered_observations Expected observations given past --sample data. predicted_observations One-step-ahead forecasts observations. filtered_states_var List filtered state variance matrices. predicted_states_var List one-step-ahead state prediction variances. predicted_observations_var List one-step-ahead observation forecast variances. mahalanobis_residuals Vector Mahalanobis distances residuals predicted observations. outliers_flagged Vector 1's 0's indicating whether timepoints flagged outlying based threshold supplied (available model class robularized_SSM).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/oos_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Out-of-Sample Inference for Fitted State Space Model — oos_filter","text":"function reuses model's fitted parameters generate inference new data y_oos. Robust variants use appropriate robust filters, classical oracle models use standard Kalman filtering. oracle_SSM models, observations flagged outlier_locs treated missing filtering.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/oracle_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Oracle State Space Model Fit — oracle_SSM","title":"Oracle State Space Model Fit — oracle_SSM","text":"Fits state space model treating known set outliers missing data. benchmark model assumes prior knowledge outlier locations intended comparison automatic outlier detection procedures.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/oracle_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oracle State Space Model Fit — oracle_SSM","text":"","code":"oracle_SSM(   y,   init_par,   build,   outlier_locs,   lower = NA,   upper = NA,   control = list(parscale = init_par) )"},{"path":"https://github.com/rajan-shankar/roams/reference/oracle_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Oracle State Space Model Fit — oracle_SSM","text":"y numeric matrix observations (time points rows). init_par numeric vector initial parameter values. build function returns dlm model given parameter vector. specify_SSM() function can used create build function. outlier_locs integer logical vector length equal number time points, indicating locations known outliers. lower Optional numeric vector lower bounds parameter estimation. Defaults -Inf. Must length init_par. upper Optional numeric vector upper bounds parameter estimation. Defaults Inf. Must length init_par. control Optional list control parameters passed optim via dlm::dlmMLE(). Default list(parscale = init_par), can help optimizer parameters vastly different scales.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/oracle_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Oracle State Space Model Fit — oracle_SSM","text":"object class oracle_SSM containing optimization result, provided outlier locations, original data, original build function.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/outlier_target_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Model Based on Target Outlier Proportion — outlier_target_model","title":"Select Model Based on Target Outlier Proportion — outlier_target_model","text":"Extracts model robularized_SSM_list object whose estimated outlier proportion closest user-specified target.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/outlier_target_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Model Based on Target Outlier Proportion — outlier_target_model","text":"","code":"outlier_target_model(model_list, target)"},{"path":"https://github.com/rajan-shankar/roams/reference/outlier_target_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Model Based on Target Outlier Proportion — outlier_target_model","text":"model_list object class robularized_SSM_list. target numeric value 0 1 indicating desired proportion outlying observations.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/outlier_target_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Model Based on Target Outlier Proportion — outlier_target_model","text":"single robularized_SSM object whose estimated outlier proportion closest target.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/outlier_target_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Model Based on Target Outlier Proportion — outlier_target_model","text":"","code":"if (FALSE) { # \\dontrun{ # Select the model with an outlier proportion closest to 10% target_model <- outlier_target_model(models, target = 0.1) } # }"},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust Regularized Fitting of State Space Models — robularized_SSM","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":"Fits robust state space model multivariate time series data using iterative parameter estimation outlier detection. procedure inspired Iterative Procedure Outlier Detection (IPOD) algorithm Owen (2011) applied sequence regularization parameters (\\(\\lambda\\)'s), identifying outliers via Mahalanobis residuals re-fitting model iteratively.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":"","code":"robularized_SSM(   y,   init_par,   build,   num_lambdas = 20,   custom_lambdas = NA,   cores = 1,   B = 50,   lower = NA,   upper = NA,   control = list(parscale = init_par) )"},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":"y numeric matrix observations, row corresponding time point. init_par numeric vector initial parameter values optimization. build function accepts parameter vector returns dlm model (used dlm::dlmMLE()). specify_SSM function can used create build function. num_lambdas Integer. number \\(\\lambda\\) values evaluate. Ignored custom_lambdas specified. Default 20. custom_lambdas Optional numeric vector. supplied, exact \\(\\lambda\\) values used model fitting. provided set NA, num_lambdas \\(\\lambda\\)'s automatically chosen. cores Integer. Number CPU cores use parallel processing. Default 1 (sequential execution). B Integer. Maximum number IPOD iterations per \\(\\lambda\\). Default 50. lower Optional numeric vector lower bounds optimization. NA, defaults -Inf parameters. Must length init_par. upper Optional numeric vector upper bounds optimization. NA, defaults Inf parameters. Must length init_par. control named list control options pass optim via dlm::dlmMLE(). Default list(parscale = init_par), can help optimizer parameters vastly different scales.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":"one \\(\\lambda\\) values used, returns object class robularized_SSM_list — list containing robularized_SSM model \\(\\lambda\\). one \\(\\lambda\\) value used (.e. custom_lambdas manually specified single value), returns single robularized_SSM object. robularized_SSM object includes: lambda - \\(\\lambda\\) value used. prop_outlying - Proportion non-missing time points identified outliers. BIC - Bayesian Information Criterion final model. loglik - Log-likelihood fitted model. RSS - Residual sum squares. gamma - Matrix estimated outlier adjustments. iterations - Number IPOD iterations performed. Optimization output dlm::dlmMLE() final IPOD iteration. y - original data matrix. build - original build function used specify model.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":"IPOD procedure alternates estimating model parameters via maximum likelihood identifying outlying observations based Mahalanobis residuals. iteration: dlm model fit using dlm::dlmMLE(). Mahalanobis residuals computed. Observations residuals current \\(\\lambda\\) threshold treated missing next iteration. algorithm stops change parameters outlier estimates sufficiently small many outliers detected (50% complete observations).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/robularized_SSM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Robust Regularized Fitting of State Space Models — robularized_SSM","text":", Y., & Owen, . B. (2011). Outlier Detection Using Nonconvex Penalized Regression. *Journal American Statistical Association, 106*(494), 626–639. https://doi.org/10.1198/jasa.2011.tm10390","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","title":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","text":"Simulates data sets first-difference correlated random walk (DCRW) state-space model Study 1 paper. study evaluates performance different types outlier configurations. arguments default values matching simulation setup used paper.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","text":"","code":"simulate_data_study1(   sample_sizes = c(100, 200, 500, 1000),   samples = 100,   n_oos = 20,   contamination = 0.1,   distance = 5,   sd_cluster = 2,   mean_cluster = c(20, 20),   multi_level_distances = c(distance - 2, distance, distance + 2),   phi_coef = 0.8,   sigma2_w_lon = 0.1,   sigma2_w_lat = 0.1,   sigma2_v_lon = 0.4,   sigma2_v_lat = 0.4,   initial_state = c(0, 0, 0, 0),   seed = NA )"},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","text":"sample_sizes Vector sample sizes \\(n\\) simulated dataset. Default c(100, 200, 500, 1000). samples Number simulated data sets per \\(n\\) per outlier configuration. Default 100. n_oos Number --sample (future) timesteps. Default 20. contamination Proportion contaminated (outlying) observations. Default 0.1. distance Distance used fixed-distance outliers. Default 5. sd_cluster Standard deviation cluster cluster-based outliers. Default 2. mean_cluster Mean vector cluster cluster-based outliers. Default c(20, 20). multi_level_distances Vector distances multi-level outliers. Must length 3. Default c(3, 5, 7). phi_coef Autocorrelation parameter DCRW transition matrix. Ranges 0 1. Default 0.8. sigma2_w_lon, sigma2_w_lat State noise variances (longitude latitude). Default 0.1 . sigma2_v_lon, sigma2_v_lat Observation noise variances (longitude latitude). Default 0.4 . initial_state Initial state vector length 4. Default c(0, 0, 0, 0). seed Optional random seed reproducibility. Default NA. Use seed = 1302 reproduce data paper.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","text":"tibble containing simulated data sets. row corresponds simulated data set includes fields sample size, outlier configuration (setting), outliers, clean data, noisy observations, --sample values.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate DCRW Data for Study 1: Different Outlier Configurations — simulate_data_study1","text":"","code":"data_study1 = simulate_data_study1(samples = 5, seed = 123)"},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"Simulates datasets first-difference correlated random walk (DCRW) state-space model Study 2 paper. study examines impact increasing contamination levels varying outlier distances model performance. arguments default values matching simulation setup used paper.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"","code":"simulate_data_study2(   samples = 100,   n = 200,   max_contamination = 0.2,   distances = c(1, 3, 5, 7, 9),   n_oos = 20,   phi_coef = 0.8,   sigma2_w_lon = 0.1,   sigma2_w_lat = 0.1,   sigma2_v_lon = 0.4,   sigma2_v_lat = 0.4,   initial_state = c(0, 0, 0, 0),   seed = NA )"},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"samples Number simulated data sets per contamination rate outlier distance. Default 100. n Number -sample timesteps. Default 200. max_contamination Maximum proportion contaminated (outlying) observations. Default 0.2. distances Vector five distances additive outliers. Must length 5. Default c(1, 3, 5, 7, 9). n_oos Number --sample (future) timesteps. Default 20. phi_coef Autocorrelation parameter DCRW transition matrix. Default 0.8. sigma2_w_lon, sigma2_w_lat State noise variances (longitude latitude). Default 0.1 . sigma2_v_lon, sigma2_v_lat Observation noise variances (longitude latitude). Default 0.4 . initial_state Initial state vector length 4. Default c(0, 0, 0, 0). seed Optional random seed reproducibility. Default NA. Use seed = 205 reproduce data paper.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"tibble containing simulated data sets. row corresponds simulated data set includes fields contamination rate, distance, outliers, clean data, noisy observations, --sample values.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"equally-spaced sequence five increasing contamination rates 0 max_contamination constructed internally. example, max_contamination = 0.2, contamination rates c(0, 0.05, 0.1, 0.15, 0.2). returned tibble \\(9\\times\\) samples rows, row corresponding unique combination contamination rate distance. levels contamination rate distance 'crossed'; rather, middle contamination rate (e.g. 0.1) crossed distances, middle distance (e.g. 5) crossed contamination rates. result \\(5\\times 1 + 5\\times 1 = 10\\) data sets. However, middle contamination rate middle distance double-counted, total number unique data sets per sample \\(10 - 1 = 9\\).","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/simulate_data_study2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate DCRW Data for Study 2: Increasing Contamination and Varying Outlier Distance — simulate_data_study2","text":"","code":"data_study2 = simulate_data_study2(samples = 5, seed = 456)"},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a State-Space Model in DLM Format — specify_SSM","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"helper function users construct state-space model format expected dlm package, package used internally model fitting functions. function returns named list model components can directly used user-defined build function passed modeling function package.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"","code":"specify_SSM(   state_transition_matrix,   state_noise_var,   observation_matrix,   observation_noise_var,   init_state_mean,   init_state_var )"},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"state_transition_matrix square matrix specifying state transition dynamics (GG). state_noise_var square matrix specifying variance state noise (W). observation_matrix matrix mapping state observations (FF). observation_noise_var square matrix specifying variance observation noise (V). init_state_mean vector specifying initial mean state (m0). init_state_var square matrix specifying initial state covariance (C0).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"named list elements GG, W, FF, V, m0, C0, suitable use custom build function modeling online filtering (e.g., using oos_filter).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"letters parentheses Arguments section correspond naming convention used dlm package.","code":""},{"path":[]},{"path":"https://github.com/rajan-shankar/roams/reference/specify_SSM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a State-Space Model in DLM Format — specify_SSM","text":"","code":"build_function = function(par) {   phi_coef = par[1]   Phi = diag(c(1+phi_coef, 1+phi_coef, 0, 0))   Phi[1,3] = -phi_coef   Phi[2,4] = -phi_coef   Phi[3,1] = 1   Phi[4,2] = 1    A = diag(4)[1:2,]   Sigma_W = diag(c(par[2], par[3], 0, 0))   Sigma_V = diag(c(par[4], par[5]))    mu0 = rep(0, 4)   P0 = diag(rep(0, 4))    specify_SSM(     state_transition_matrix = Phi,     state_noise_var = Sigma_W,     observation_matrix = A,     observation_noise_var = Sigma_V,     init_state_mean = mu0,     init_state_var = P0   ) }"},{"path":"https://github.com/rajan-shankar/roams/reference/trimmed_robust_SSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","title":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","text":"Fits robust state space model minimizing trimmed loss function per Crevits Croux (2018). fixed proportion largest residuals excluded objective, providing robustness extreme outliers. predicted observations used trimmed loss computed using Huber robust filter Cipra Romera (1997).","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/trimmed_robust_SSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","text":"","code":"trimmed_robust_SSM(   y,   init_par,   build,   alpha,   lower = NA,   upper = NA,   control = list(parscale = init_par) )"},{"path":"https://github.com/rajan-shankar/roams/reference/trimmed_robust_SSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","text":"y numeric matrix observations (time points rows). init_par numeric vector initial parameter values. build function returns dlm model given parameter vector. specify_SSM() function can used create build function. alpha Numeric value interval [0, 1) indicating trimming proportion (.e., proportion data exclude outliers). lower Optional numeric vector lower bounds parameter estimation. Defaults -Inf. Must length init_par. upper Optional numeric vector upper bounds parameter estimation. Defaults Inf. Must length init_par. control Optional list control parameters passed optim. Default list(parscale = init_par), can help optimizer parameters vastly different scales.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/trimmed_robust_SSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","text":"object class trimmed_robust_SSM containing optimization result, trimming level \\(\\alpha\\), original data, original build function.","code":""},{"path":"https://github.com/rajan-shankar/roams/reference/trimmed_robust_SSM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trimmed-Robust State Space Model Fit — trimmed_robust_SSM","text":"Crevits R. Croux C. (2018). Robust Estimation Linear State Space Models. *Communications Statistics: Simulation Computation* Cipra, T., Romera, R. (1997). Kalman filter outliers missing observations. *Test* 6, 379–395. https://doi.org/10.1007/BF02564705","code":""},{"path":[]}]
